{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "successful-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenic.simulators.gfootball import rl_interface\n",
    "from stable_baselines3 import PPO\n",
    "from scenic.simulators.gfootball.rl_interface import GFScenicEnv\n",
    "#import pretrain_template\n",
    "#from gfootball_impala_cnn import GfootballImpalaCNN\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from stable_baselines3 import PPO, A2C, SAC, TD3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from torch.utils.data.dataset import Dataset, random_split\n",
    "import os\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.preprocessing import is_image_space\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "import torch as th\n",
    "import torch\n",
    "import os\n",
    "from scenic.simulators.gfootball.utilities.scenic_helper import buildScenario\n",
    "from helper import *\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "downtown-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_expert_data import generate_expert_data, generate_expert_data_with_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "broke-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment will ignore actions passed to step() and take action provided by Scenic\n"
     ]
    }
   ],
   "source": [
    "#generate expert data\n",
    "num_interactions = 2500\n",
    "expert_data_file = f\"expert_data/pass_n_shoot_{num_interactions}\"\n",
    "\n",
    "\n",
    "#create data_gen_environment\n",
    "gf_env_settings = {\n",
    "    \"stacked\": True,\n",
    "    \"rewards\": 'scoring',\n",
    "    \"representation\": 'extracted',\n",
    "    \"players\": [f\"agent:left_players=1\"],\n",
    "    \"real_time\": False,\n",
    "    \"action_set\": \"default\",#\"default\" \"v2\"\n",
    "}\n",
    "\n",
    "datagen_scenario_file = f\"{cwd}/pass_n_shoot_wb.scenic\"\n",
    "datagen_scenario = buildScenario(datagen_scenario_file)\n",
    "from scenic.simulators.gfootball.rl_interface import GFScenicEnv\n",
    "\n",
    "#import scenic.syntax.veneer as veneer\n",
    "#veneer.reset()\n",
    "\n",
    "datagen_env = GFScenicEnv(initial_scenario=datagen_scenario, gf_env_settings=gf_env_settings, use_scenic_behavior_in_step=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "regulated-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward and STD of Scenic Behavior Agent (0.6, 0.48989794855663565)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Reward and STD of Scenic Behavior Agent\", mean_perf_random_agent(datagen_env, num_trials=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "scenic-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:15<00:00, 161.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert observation shape:  (2500, 16, 72, 96)\n",
      "Expert actions shape:  (2500,)\n"
     ]
    }
   ],
   "source": [
    "expert_observations, expert_actions, expert_rewards = generate_expert_data_with_rewards(datagen_env, num_interactions=num_interactions, file_name=expert_data_file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "blond-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = [0]*51 + [1]*49\n",
    "#print(np.mean(x), np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "activated-disney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert data mean, std rewards, and total episodes:\n",
      " 0.546875 0.4977978850648122 64\n"
     ]
    }
   ],
   "source": [
    "print(\"expert data mean, std rewards, and total episodes:\\n\", np.mean(expert_rewards), np.std(expert_rewards), expert_rewards.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
