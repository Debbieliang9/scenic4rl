{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26d3aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code is used to train BC imitator, or pretrained GAIL imitator\n",
    "'''\n",
    "\n",
    "import argparse\n",
    "import tempfile\n",
    "import os.path as osp\n",
    "import gym\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from baselines.gail import mlp_policy\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "from baselines.common import set_global_seeds, tf_util as U\n",
    "from baselines.common.misc_util import boolean_flag\n",
    "\n",
    "#from baselines.gail.run_mujoco import runner\n",
    "from baselines.gail.dataset.mujoco_dset import Mujoco_Dset \n",
    "\n",
    "##from baselines.common.mpi_adam import MpiAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd60a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gfrl.base.run_my_ppo2 import create_single_scenic_environment\n",
    "network = \"gfootball_impala_cnn\"\n",
    "scenario = \"../_scenarios/academy/pass_n_shoot.scenic\"\n",
    "load_path = \"/home/ubuntu/ScenicGFootBall/training/gfrl/_saved_models/pass_shoot_5M\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7ccb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.7/site-packages/scenic/core/errors.py:160: UserWarning: unable to install sys.excepthook to format Scenic backtraces\n",
      "  warnings.warn('unable to install sys.excepthook to format Scenic backtraces')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenic Environment:  ../_scenarios/academy/pass_n_shoot.scenic\n",
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/misc_util.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/tf_util.py:53: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/ppo2/model.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/ppo2/model.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/input.py:31: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/sonnet/python/modules/conv.py:325: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/sonnet/python/modules/conv.py:330: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/policies.py:43: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/a2c/utils.py:61: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/distributions.py:200: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/distributions.py:201: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/ppo2/model.py:95: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/ppo2/model.py:100: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/tf_util.py:89: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/common/tf_util.py:90: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/ppo2/model.py:129: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/baselines/ppo2/model.py:129: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import multiprocessing\n",
    "\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "vec_env = DummyVecEnv([lambda _i=i: \\\n",
    "                        create_single_scenic_environment(_i,scenario) for i in\n",
    "                        range(1)])\n",
    "\n",
    "\n",
    "\n",
    "ncpu = multiprocessing.cpu_count()\n",
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                        intra_op_parallelism_threads=ncpu,\n",
    "                        inter_op_parallelism_threads=ncpu)\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config=config).__enter__()\n",
    "\n",
    "from gfrl.common.mybase import ppo2\n",
    "model = ppo2.learn(\n",
    "    network=network,\n",
    "    total_timesteps=0,\n",
    "    env=vec_env,\n",
    "    nsteps=512,\n",
    "    load_path=load_path\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83f79da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenic Environment:  ../_scenarios/academy/pass_n_shoot.scenic\n",
      "in run\n"
     ]
    }
   ],
   "source": [
    "from gfrl.dm.my_runner import MyTrajRunner\n",
    "\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "vec_env = DummyVecEnv([lambda _i=i: \\\n",
    "                        create_single_scenic_environment(_i,scenario) for i in\n",
    "                        range(1)])\n",
    "\n",
    "runner = MyTrajRunner(env=vec_env, model=model, nsteps=512, num_episodes=200)\n",
    "mb_obs, mb_rewards, mb_dones, mb_actions, mb_values, mb_neglogpacs, mb_states, epinfos, mb_gt = runner.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b63edb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031296574"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(mb_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f845477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6039, 72, 96, 16) (6039,)\n"
     ]
    }
   ],
   "source": [
    "print(mb_obs.shape, mb_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec1851ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6039, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_actions.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c5b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "541ceb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_act_oh = np.zeros((mb_actions.shape[0], mb_actions.max()+1))\n",
    "mb_act_oh[np.arange(mb_actions.shape[0]), mb_actions] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4948155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6039, 19)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_act_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dec89eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  9,  9,  9, 13])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_actions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e8478ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_act_oh[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4140f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_file_name = \"../_data/pns_200.npz\"\n",
    "import numpy as np \n",
    "np.savez(expert_file_name, obs=mb_obs, acs=mb_act_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97c0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#expert_file_name = \"../_data/pns_100.npz\"\n",
    "#import numpy as np \n",
    "#np.savez(expert_file_name, obs=mb_obs, acs=mb_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d36815ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = np.load(expert_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7810278a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obs', 'acs']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(td.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45470961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dset(object):\n",
    "    def __init__(self, inputs, labels, randomize):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        assert len(self.inputs) == len(self.labels)\n",
    "        self.randomize = randomize\n",
    "        self.num_pairs = len(inputs)\n",
    "        self.init_pointer()\n",
    "\n",
    "    def init_pointer(self):\n",
    "        self.pointer = 0\n",
    "        if self.randomize:\n",
    "            idx = np.arange(self.num_pairs)\n",
    "            np.random.shuffle(idx)\n",
    "            self.inputs = self.inputs[idx, :]\n",
    "            self.labels = self.labels[idx, :]\n",
    "\n",
    "    def get_next_batch(self, batch_size):\n",
    "        # if batch_size is negative -> return all\n",
    "        if batch_size < 0:\n",
    "            return self.inputs, self.labels\n",
    "        if self.pointer + batch_size >= self.num_pairs:\n",
    "            self.init_pointer()\n",
    "        end = self.pointer + batch_size\n",
    "        inputs = self.inputs[self.pointer:end, :]\n",
    "        labels = self.labels[self.pointer:end, :]\n",
    "        self.pointer = end\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f40d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFDset(object):\n",
    "    def __init__(self, expert_path):\n",
    "        traj_data = np.load(expert_path)\n",
    "        self.inputs = traj_data[\"obs\"]\n",
    "        self.labels = labels[\"acs\"]\n",
    "        assert len(self.inputs) == len(self.labels)\n",
    "        self.randomize = randomize\n",
    "        self.num_pairs = len(inputs)\n",
    "        self.init_pointer()\n",
    "\n",
    "    def init_pointer(self):\n",
    "        self.pointer = 0\n",
    "        if self.randomize:\n",
    "            idx = np.arange(self.num_pairs)\n",
    "            np.random.shuffle(idx)\n",
    "            self.inputs = self.inputs[idx, :]\n",
    "            self.labels = self.labels[idx, :]\n",
    "\n",
    "    def get_next_batch(self, batch_size):\n",
    "        # if batch_size is negative -> return all\n",
    "        if batch_size < 0:\n",
    "            return self.inputs, self.labels\n",
    "        if self.pointer + batch_size >= self.num_pairs:\n",
    "            self.init_pointer()\n",
    "        end = self.pointer + batch_size\n",
    "        inputs = self.inputs[self.pointer:end, :]\n",
    "        labels = self.labels[self.pointer:end, :]\n",
    "        self.pointer = end\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "732f422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujocoEditDset(Dset):\n",
    "    \n",
    "    def __init__(self, expert_path, train_fraction=0.7, traj_limitation=-1, randomize=True):\n",
    "        traj_data = np.load(expert_path)\n",
    "        if traj_limitation < 0:\n",
    "            traj_limitation = len(traj_data['obs'])\n",
    "        obs = traj_data['obs'][:traj_limitation]\n",
    "        acs = traj_data['acs'][:traj_limitation]\n",
    "\n",
    "        \"\"\"\n",
    "        # obs, acs: shape (N, L, ) + S where N = # episodes, L = episode length\n",
    "        # and S is the environment observation/action space.\n",
    "        # Flatten to (N * L, prod(S))\n",
    "        if len(obs.shape) > 2:\n",
    "            self.obs = np.reshape(obs, [-1, np.prod(obs.shape[2:])])\n",
    "            self.acs = np.reshape(acs, [-1, np.prod(acs.shape[2:])])\n",
    "        else:\n",
    "            self.obs = np.vstack(obs)\n",
    "            self.acs = np.vstack(acs)\n",
    "        \"\"\"\n",
    "\n",
    "        self.rets = traj_data['ep_rets'][:traj_limitation]\n",
    "        self.avg_ret = sum(self.rets)/len(self.rets)\n",
    "        self.std_ret = np.std(np.array(self.rets))\n",
    "        if len(self.acs) > 2:\n",
    "            self.acs = np.squeeze(self.acs)\n",
    "        assert len(self.obs) == len(self.acs)\n",
    "        self.num_traj = min(traj_limitation, len(traj_data['obs']))\n",
    "        self.num_transition = len(self.obs)\n",
    "        self.randomize = randomize\n",
    "        self.dset = Dset(self.obs, self.acs, self.randomize)\n",
    "        # for behavior cloning\n",
    "        self.train_set = Dset(self.obs[:int(self.num_transition*train_fraction), :],\n",
    "                              self.acs[:int(self.num_transition*train_fraction), :],\n",
    "                              self.randomize)\n",
    "        self.val_set = Dset(self.obs[int(self.num_transition*train_fraction):, :],\n",
    "                            self.acs[int(self.num_transition*train_fraction):, :],\n",
    "                            self.randomize)\n",
    "        self.log_info()\n",
    "\n",
    "    def log_info(self):\n",
    "        logger.log(\"Total trajectories: %d\" % self.num_traj)\n",
    "        logger.log(\"Total transitions: %d\" % self.num_transition)\n",
    "        logger.log(\"Average returns: %f\" % self.avg_ret)\n",
    "        logger.log(\"Std for returns: %f\" % self.std_ret)\n",
    "\n",
    "    def get_next_batch(self, batch_size, split=None):\n",
    "        if split is None:\n",
    "            return self.dset.get_next_batch(batch_size)\n",
    "        elif split == 'train':\n",
    "            return self.train_set.get_next_batch(batch_size)\n",
    "        elif split == 'val':\n",
    "            return self.val_set.get_next_batch(batch_size)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def plot(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.hist(self.rets)\n",
    "        plt.savefig(\"histogram_rets.png\")\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3111b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenic Environment:  ../_scenarios/academy/pass_n_shoot.scenic\n"
     ]
    }
   ],
   "source": [
    "from gfrl.base.run_my_ppo2 import create_single_scenic_environment\n",
    "    \n",
    "scenario = \"../_scenarios/academy/pass_n_shoot.scenic\"\n",
    "env = create_single_scenic_environment(0,scenario)\n",
    "\n",
    "from baselines.common.policies import build_policy\n",
    "network = \"gfootball_impala_cnn\"\n",
    "#Check Network parameters\n",
    "network_kwargs = {}\n",
    "policy_fn = build_policy(env, network, **network_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e93a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "policy_with_value = policy_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcdcf739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<baselines.common.policies.PolicyWithValue at 0x7ff2c7cf6ad0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_with_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17cd1867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_evaluate',\n",
       " 'action',\n",
       " 'initial_state',\n",
       " 'load',\n",
       " 'neglogp',\n",
       " 'pd',\n",
       " 'pdtype',\n",
       " 'pi',\n",
       " 'save',\n",
       " 'sess',\n",
       " 'state',\n",
       " 'step',\n",
       " 'value',\n",
       " 'vf']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cb6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
